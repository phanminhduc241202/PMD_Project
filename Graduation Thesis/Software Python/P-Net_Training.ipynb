{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ed2f921-77fe-484a-9071-3bd1d0aadedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time\n",
    "import copy\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from MTCNN_nets import PNet  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41d6650d-75da-43ba-b062-807f424083a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ListDataset(Dataset):\n",
    "    def __init__(self, list_path):\n",
    "        with open(list_path, 'r') as file:\n",
    "            self.img_files = [line.strip() for line in file if line.strip()]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.img_files)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        annotation = self.img_files[index].split()\n",
    "        img_path = annotation[0]\n",
    "        img = cv2.imread(img_path)\n",
    "        if img is None:\n",
    "            raise FileNotFoundError(f\"Image {img_path} not found\")\n",
    "        img = img[:, :, ::-1]\n",
    "        img = np.asarray(img, 'float32')\n",
    "        img = img.transpose((2, 0, 1))\n",
    "        img = (img - 127.5) * 0.0078125\n",
    "        input_img = torch.FloatTensor(img)\n",
    "        \n",
    "        label = int(annotation[1])\n",
    "        bbox_target = np.zeros(4, dtype=np.float32)\n",
    "        if label != 0 and len(annotation) == 6:\n",
    "            bbox_target = np.array([float(x) for x in annotation[2:]], dtype=np.float32)\n",
    "        \n",
    "        return {\n",
    "            'input_img': input_img,\n",
    "            'label': label,\n",
    "            'bbox_target': bbox_target\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1712a2bd-59ce-4698-a3c7-f0dd7b299d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Conv2d) or isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_uniform_(m.weight.data)\n",
    "        nn.init.constant_(m.bias, 0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da3a441d-c2af-4ab3-ab56-50a459f85671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda:0\n",
      "NVIDIA GeForce GTX 1650\n",
      "Memory Allocated: 0\n",
      "Memory Cached: 0\n"
     ]
    }
   ],
   "source": [
    "train_path = \"C:/Minh_Duc/MD_Personal/LVTN/Training_MTCNN/output/anno_store/imglist_anno_12_train.txt\"\n",
    "val_path = \"C:/Minh_Duc/MD_Personal/LVTN/Training_MTCNN/output/anno_store/imglist_anno_12_val.txt\"\n",
    "batch_size = 32\n",
    "num_epochs = 15\n",
    "\n",
    "# Tạo thư mục lưu biểu đồ nếu chưa tồn tại\n",
    "os.makedirs(\"C:/Minh_Duc/MD_Personal/LVTN/Training_MTCNN/plots\", exist_ok=True)\n",
    "\n",
    "# Load dữ liệu\n",
    "dataloaders = {\n",
    "    'train': DataLoader(ListDataset(train_path), batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True),\n",
    "    'val': DataLoader(ListDataset(val_path), batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "}\n",
    "dataset_sizes = {x: len(ListDataset(p)) for x, p in zip(['train', 'val'], [train_path, val_path])}\n",
    "\n",
    "# Thiết bị\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f'Using device: {device}')\n",
    "if device.type == 'cuda':\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "    print('Memory Allocated:', torch.cuda.memory_allocated(0))\n",
    "    print('Memory Cached:', torch.cuda.memory_reserved(0))\n",
    "# Mô hình\n",
    "model = PNet(is_train=True).to(device)\n",
    "model.apply(weights_init)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "loss_cls = nn.CrossEntropyLoss()\n",
    "loss_offset = nn.MSELoss()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7defe8dd-72b6-4092-adfe-a68ee328ec74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 0/14\n",
      "--------------------\n"
     ]
    }
   ],
   "source": [
    "# Lưu log\n",
    "train_loss_log, val_loss_log = [], []\n",
    "train_cls_loss_log, val_cls_loss_log = [], []\n",
    "train_offset_loss_log, val_offset_loss_log = [], []\n",
    "train_acc_log, val_acc_log = [], []\n",
    "\n",
    "best_model_wts = copy.deepcopy(model.state_dict())\n",
    "best_loss = float('inf')\n",
    "\n",
    "since = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f'\\nEpoch {epoch}/{num_epochs-1}')\n",
    "    print('-' * 20)\n",
    "    for phase in ['train', 'val']:\n",
    "        model.train() if phase == 'train' else model.eval()\n",
    "        running_loss = running_loss_cls = running_loss_offset = running_correct = running_gt = 0.0\n",
    "\n",
    "        for sample_batched in dataloaders[phase]:\n",
    "            inputs = sample_batched['input_img'].to(device)\n",
    "            gt_label = sample_batched['label'].to(device)\n",
    "            gt_offset = sample_batched['bbox_target'].to(device).float()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            with torch.set_grad_enabled(phase == 'train'):\n",
    "                pred_offset, pred_label = model(inputs)\n",
    "                pred_label = pred_label.mean(dim=[2, 3])\n",
    "                pred_offset = pred_offset.mean(dim=[2, 3])\n",
    "\n",
    "                mask_cls = gt_label >= 0\n",
    "                valid_gt_label = gt_label[mask_cls]\n",
    "                valid_pred_label = pred_label[mask_cls]\n",
    "\n",
    "                cls_loss = torch.tensor(0.0, device=device)\n",
    "                eval_correct = 0\n",
    "                if len(valid_gt_label) > 0:\n",
    "                    cls_loss = loss_cls(valid_pred_label, valid_gt_label)\n",
    "                    pred = torch.max(valid_pred_label, 1)[1]\n",
    "                    eval_correct = (pred == valid_gt_label).sum().item()\n",
    "\n",
    "                mask_offset = gt_label != 0\n",
    "                valid_gt_offset = gt_offset[mask_offset]\n",
    "                valid_pred_offset = pred_offset[mask_offset]\n",
    "\n",
    "                offset_loss = torch.tensor(0.0, device=device)\n",
    "                if len(valid_gt_offset) > 0:\n",
    "                    offset_loss = loss_offset(valid_pred_offset, valid_gt_offset)\n",
    "\n",
    "                loss = 0.02 * cls_loss + 0.6 * offset_loss if (cls_loss > 0 or offset_loss > 0) else cls_loss\n",
    "\n",
    "                if phase == 'train':\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "            running_loss += loss.item() * inputs.size(0)\n",
    "            running_loss_cls += cls_loss.item() * inputs.size(0)\n",
    "            running_loss_offset += offset_loss.item() * inputs.size(0)\n",
    "            running_correct += eval_correct\n",
    "            running_gt += len(valid_gt_label)\n",
    "\n",
    "        epoch_loss = running_loss / dataset_sizes[phase]\n",
    "        epoch_cls_loss = running_loss_cls / dataset_sizes[phase]\n",
    "        epoch_offset_loss = running_loss_offset / dataset_sizes[phase]\n",
    "        epoch_acc = running_correct / (running_gt + 1e-16)\n",
    "\n",
    "        print(f'{phase} - Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.4f}, '\n",
    "              f'Cls Loss: {epoch_cls_loss:.4f}, Offset Loss: {epoch_offset_loss:.4f}')\n",
    "\n",
    "        if phase == 'train':\n",
    "            train_loss_log.append(epoch_loss)\n",
    "            train_cls_loss_log.append(epoch_cls_loss)\n",
    "            train_offset_loss_log.append(epoch_offset_loss)\n",
    "            train_acc_log.append(epoch_acc)\n",
    "        else:\n",
    "            val_loss_log.append(epoch_loss)\n",
    "            val_cls_loss_log.append(epoch_cls_loss)\n",
    "            val_offset_loss_log.append(epoch_offset_loss)\n",
    "            val_acc_log.append(epoch_acc)\n",
    "            if epoch_loss < best_loss:\n",
    "                best_loss = epoch_loss\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c29f5e43-e3c0-498d-a712-3b2e73433da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load và lưu mô hình tốt nhất\n",
    "model.load_state_dict(best_model_wts)\n",
    "save_path = \"C:/Minh_Duc/MD_Personal/LVTN/Training_MTCNN/weights/Pnet_weight_v2.pth\"\n",
    "torch.save(model.state_dict(), save_path)\n",
    "\n",
    "print(f\"\\nTraining complete. Best val loss: {best_loss:.4f}\")\n",
    "print(f\"Model weights saved to {save_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567a6f67-7762-4cb1-81a0-f2077b778be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = list(range(num_epochs))\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(epochs, train_loss_log, label='Train Loss')\n",
    "plt.plot(epochs, val_loss_log, label='Val Loss')\n",
    "plt.title('Total Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(epochs, train_cls_loss_log, label='Train Cls Loss')\n",
    "plt.plot(epochs, val_cls_loss_log, label='Val Cls Loss')\n",
    "plt.title('Classification Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(epochs, train_offset_loss_log, label='Train Offset Loss')\n",
    "plt.plot(epochs, val_offset_loss_log, label='Val Offset Loss')\n",
    "plt.title('Offset Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "plt.plot(epochs, train_acc_log, label='Train Accuracy')\n",
    "plt.plot(epochs, val_acc_log, label='Val Accuracy')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"C:/Minh_Duc/MD_Personal/LVTN/Training_MTCNN/plots/pnet_training_curves.png\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
